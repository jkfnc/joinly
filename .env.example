# for OpenAI LLM
# change key and model to your desired one
JOINLY_MODEL_NAME=gpt-4o
JOINLY_MODEL_PROVIDER=openai
OPENAI_API_KEY=your-openai-api-key

# for Anthropic LLM
# change key and model to your desired one
JOINLY_MODEL_NAME=claude-3-5-haiku-latest
JOINLY_MODEL_PROVIDER=anthropic
ANTHROPIC_API_KEY=your-anthropic-api-key

# for Azure OpenAI LLM
# change key and model to your desired one (and version)
JOINLY_MODEL_NAME=gpt-4o
JOINLY_MODEL_PROVIDER=azure_openai
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
AZURE_OPENAI_ENDPOINT=https://your-azure-openai-endpoint.openai.azure.com/
OPENAI_API_VERSION=2024-12-01-preview

# for Ollama LLM (requires ollama pull <model>)
# Note: only works when using the client_example.py, or another script outside of the docker,
# for direct usage with --client, you would need additional setup
# note that small models often fail to correctly call the necessary tools, so try with caution
# change to your desired model with tool calling
JOINLY_MODEL_NAME=smollm2:1.7b
JOINLY_MODEL_PROVIDER=ollama
# for Ollama at a different host, set following variables to your desired host and port:
# OLLAMA_HOST=127.0.0.1
# OLLAMA_PORT=11434

# Deepgram Text-to-Speech/Transcription, set args "--tts deepgram" or/and "--stt deepgram"
DEEPGRAM_API_KEY=your-deepgram-api-key

# For the example client (tavily web search)
TAVILY_API_KEY=your-tavily-api-key
